{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training a Neural Network on Scikit's Make Circles\r\n",
    "\"Make circles\" is a popular dataset to test whether machine learning models are able to properly fit non-linear data. Although XOR is the simplest dataset to verify this with, make circles allows for validation testing and for visualizing predictions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. The Dataset\r\n",
    "Let's get a better look at what make_circles is. According to make_circle's documentation:\r\n",
    "\r\n",
    "_Makes a large circle containing a smaller circle in 2d._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import dataset and other necessary modules\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.datasets import make_circles\r\n",
    "from ml_functions.plots import display_data\r\n",
    "\r\n",
    "# Generate Dataset\r\n",
    "X, y = make_circles(n_samples=200, noise=0.1, random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`make_circles()` has a few important parameters that are worth taking note of:\r\n",
    "\r\n",
    "  * n_samples - The _total_ number of points. I set it here to 200, that way both the inner and the outer circle each have 100 points.\r\n",
    "  * noise - Defines the stanard deviation of gaussian noise for the data. 0.1 allows for some amount of noise, while maintaining the general circular shape.\r\n",
    "  * random_state - This serves as a seed, and it used so that results are reproducible.\r\n",
    "\r\n",
    "Let's plot the data. I have made a function `display_data()` that will automatically plot 2D data like this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot dataset\r\n",
    "display_data(X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, there is a clear outer and inner circle. Thus, it is expected for the model to be able to learn this relationship.\r\n",
    "\r\n",
    "Now, let's create the training and test sets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reshape the data. Will not work in the network model unless this is done.\r\n",
    "X = np.reshape(X,(100,1,2))\r\n",
    "y = np.reshape(y,(100,1,1)) \r\n",
    "\r\n",
    "# Creates a training/test split of 150/50\r\n",
    "training_count = 150\r\n",
    "X_train, X_test = X[:training_count, :], X[training_count:, :]\r\n",
    "y_train, y_test = y[:training_count], y[training_count:]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Doing such a training/test split would normally be unacceptable (non-random, most likely non-optimal ratio). As this is a toy scenario, it is safe to ignore this issue and move on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Neural Network\r\n",
    "We can create a neural network model and train it on the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Neural Network Imports\r\n",
    "from neural_network.layers.activation_layer import ActivationLayer\r\n",
    "from neural_network.layers.dense_layer import DenseLayer\r\n",
    "\r\n",
    "from neural_network.network import NeuralNetwork\r\n",
    "\r\n",
    "# Create network\r\n",
    "network = NeuralNetwork(\r\n",
    "    DenseLayer(2, 500),\r\n",
    "    ActivationLayer('relu'),\r\n",
    "    DenseLayer(500, 1),\r\n",
    "    ActivationLayer('sigmoid')\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The architecture is a 3 layer, fully-connected, deep neural network that has the following layer structure:\r\n",
    "* input size of 2 ((x,y) coordinates)\r\n",
    "* fully-connected layer with 256 neurons and has ReLU activation\r\n",
    "* fully-connected output layer with 1 neuron and sigmoid activation\r\n",
    "\r\n",
    "Following the sigmoid activation, if `output > 0.5`, then the network will choose class 1. Otherwise, it will choose class 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fits the model. Verbose is turned off as epochs is at 5000\r\n",
    "history = network.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5000, lr=0.001, verbose=False)\r\n",
    "\r\n",
    "# Gets training and testing accuracy\r\n",
    "train_acc = network.evaluate(X_train, y_train)\r\n",
    "test_acc = network.evaluate(X_test, y_test)\r\n",
    "\r\n",
    "print('Train: {%.5f}, Test: {%.5f}'.format(train_acc, test_acc))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, the model has overfitted on the data. This can be mitigated, but shows that the network is learning on the data, which is the main goal of this notebook.\r\n",
    "\r\n",
    "Here is the training history visualized."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# Plot the history\r\n",
    "plt.plot(history['accuracy'], label='training data')\r\n",
    "plt.plot(history['val_accuracy'], label='testing data')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can show that the network was able to make a generalization of the data with a heatmap."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import heatmap visualization\r\n",
    "from ml_functions.plots import display_prediction_heatmap\r\n",
    "\r\n",
    "# Creates a heatmap in the 2D box [-1,-1] to [1,1]. An accuracy of 100 gives a good resolution\r\n",
    "# without spending too much computation time\r\n",
    "display_prediction_heatmap(network, -1, 1, -1, 1, acc=100)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "82fdbad23d1d7218fe061e4c560b85ec5032b2830716faa690995c31c64b0a4d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}